{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Sentence_Similarity_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiWwWSVmiKXKV8rKHjlSWq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0a3154ddbdaf4387b8be1e365cc10819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b9b34455a34c48efa7e62732a910d993",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eb468c05924049d980fd5085b291c9d0",
              "IPY_MODEL_4a5cf94e30a145ce9bc85caca5b900d8"
            ]
          }
        },
        "b9b34455a34c48efa7e62732a910d993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb468c05924049d980fd5085b291c9d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_39dd1ad0648f41bcbfe0433a57f07021",
            "_dom_classes": [],
            "description": "Batches: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 6250,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6250,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f103bd351154536bfc73c240396e997"
          }
        },
        "4a5cf94e30a145ce9bc85caca5b900d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad4354944e2442fc8b7f295551100568",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6250/6250 [04:45&lt;00:00, 21.91it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21571df0bc514890b6e96c6d5da2ef6e"
          }
        },
        "39dd1ad0648f41bcbfe0433a57f07021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f103bd351154536bfc73c240396e997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad4354944e2442fc8b7f295551100568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21571df0bc514890b6e96c6d5da2ef6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveentn/hgwxx7/blob/master/%5Cnlp%5Csimilarity%5Cbert_sentence_similarity_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwRWXgiHJVlF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "dd42ddc2-e043-467e-b740-9a6e6235481f"
      },
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/71/acfb3f1016f83d90590130dc2ee0d8cd36b005aa7afa45b465837b711070/sentence-transformers-0.3.3.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.3MB/s \n",
            "\u001b[?25hCollecting transformers>=3.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\u001b[K     |████████████████████████████████| 778kB 13.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (0.7)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 44.3MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (2019.12.20)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers) (20.4)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.2->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=3.0.2->sentence-transformers) (2.4.7)\n",
            "Building wheels for collected packages: sentence-transformers, sacremoses\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.3-cp36-none-any.whl size=97299 sha256=31e8b9dbca1fc959f48e24d237281a05adcad7739f5450f8436809af5d7e736f\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/d6/0a/cab163b21d0597cc1580bc344487b11ad405e0d1d314725f2b\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=fe1bae775844ba9c13c8a15cf80762146c45fb641ef3fee8249078f35978e4c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sentence-transformers sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers, sentence-transformers\n",
            "Successfully installed sacremoses-0.0.43 sentence-transformers-0.3.3 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj_cL2nKJZk5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7d239777-e3b1-4b98-ed49-2b830dfe7b2d"
      },
      "source": [
        "!git clone https://github.com/UKPLab/sentence-transformers.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'sentence-transformers'...\n",
            "remote: Enumerating objects: 151, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/151)\u001b[K\rremote: Counting objects:   1% (2/151)\u001b[K\rremote: Counting objects:   2% (4/151)\u001b[K\rremote: Counting objects:   3% (5/151)\u001b[K\rremote: Counting objects:   4% (7/151)\u001b[K\rremote: Counting objects:   5% (8/151)\u001b[K\rremote: Counting objects:   6% (10/151)\u001b[K\rremote: Counting objects:   7% (11/151)\u001b[K\rremote: Counting objects:   8% (13/151)\u001b[K\rremote: Counting objects:   9% (14/151)\u001b[K\rremote: Counting objects:  10% (16/151)\u001b[K\rremote: Counting objects:  11% (17/151)\u001b[K\rremote: Counting objects:  12% (19/151)\u001b[K\rremote: Counting objects:  13% (20/151)\u001b[K\rremote: Counting objects:  14% (22/151)\u001b[K\rremote: Counting objects:  15% (23/151)\u001b[K\rremote: Counting objects:  16% (25/151)\u001b[K\rremote: Counting objects:  17% (26/151)\u001b[K\rremote: Counting objects:  18% (28/151)\u001b[K\rremote: Counting objects:  19% (29/151)\u001b[K\rremote: Counting objects:  20% (31/151)\u001b[K\rremote: Counting objects:  21% (32/151)\u001b[K\rremote: Counting objects:  22% (34/151)\u001b[K\rremote: Counting objects:  23% (35/151)\u001b[K\rremote: Counting objects:  24% (37/151)\u001b[K\rremote: Counting objects:  25% (38/151)\u001b[K\rremote: Counting objects:  26% (40/151)\u001b[K\rremote: Counting objects:  27% (41/151)\u001b[K\rremote: Counting objects:  28% (43/151)\u001b[K\rremote: Counting objects:  29% (44/151)\u001b[K\rremote: Counting objects:  30% (46/151)\u001b[K\rremote: Counting objects:  31% (47/151)\u001b[K\rremote: Counting objects:  32% (49/151)\u001b[K\rremote: Counting objects:  33% (50/151)\u001b[K\rremote: Counting objects:  34% (52/151)\u001b[K\rremote: Counting objects:  35% (53/151)\u001b[K\rremote: Counting objects:  36% (55/151)\u001b[K\rremote: Counting objects:  37% (56/151)\u001b[K\rremote: Counting objects:  38% (58/151)\u001b[K\rremote: Counting objects:  39% (59/151)\u001b[K\rremote: Counting objects:  40% (61/151)\u001b[K\rremote: Counting objects:  41% (62/151)\u001b[K\rremote: Counting objects:  42% (64/151)\u001b[K\rremote: Counting objects:  43% (65/151)\u001b[K\rremote: Counting objects:  44% (67/151)\u001b[K\rremote: Counting objects:  45% (68/151)\u001b[K\rremote: Counting objects:  46% (70/151)\u001b[K\rremote: Counting objects:  47% (71/151)\u001b[K\rremote: Counting objects:  48% (73/151)\u001b[K\rremote: Counting objects:  49% (74/151)\u001b[K\rremote: Counting objects:  50% (76/151)\u001b[K\rremote: Counting objects:  51% (78/151)\u001b[K\rremote: Counting objects:  52% (79/151)\u001b[K\rremote: Counting objects:  53% (81/151)\u001b[K\rremote: Counting objects:  54% (82/151)\u001b[K\rremote: Counting objects:  55% (84/151)\u001b[K\rremote: Counting objects:  56% (85/151)\u001b[K\rremote: Counting objects:  57% (87/151)\u001b[K\rremote: Counting objects:  58% (88/151)\u001b[K\rremote: Counting objects:  59% (90/151)\u001b[K\rremote: Counting objects:  60% (91/151)\u001b[K\rremote: Counting objects:  61% (93/151)\u001b[K\rremote: Counting objects:  62% (94/151)\u001b[K\rremote: Counting objects:  63% (96/151)\u001b[K\rremote: Counting objects:  64% (97/151)\u001b[K\rremote: Counting objects:  65% (99/151)\u001b[K\rremote: Counting objects:  66% (100/151)\u001b[K\rremote: Counting objects:  67% (102/151)\u001b[K\rremote: Counting objects:  68% (103/151)\u001b[K\rremote: Counting objects:  69% (105/151)\u001b[K\rremote: Counting objects:  70% (106/151)\u001b[K\rremote: Counting objects:  71% (108/151)\u001b[K\rremote: Counting objects:  72% (109/151)\u001b[K\rremote: Counting objects:  73% (111/151)\u001b[K\rremote: Counting objects:  74% (112/151)\u001b[K\rremote: Counting objects:  75% (114/151)\u001b[K\rremote: Counting objects:  76% (115/151)\u001b[K\rremote: Counting objects:  77% (117/151)\u001b[K\rremote: Counting objects:  78% (118/151)\u001b[K\rremote: Counting objects:  79% (120/151)\u001b[K\rremote: Counting objects:  80% (121/151)\u001b[K\rremote: Counting objects:  81% (123/151)\u001b[K\rremote: Counting objects:  82% (124/151)\u001b[K\rremote: Counting objects:  83% (126/151)\u001b[K\rremote: Counting objects:  84% (127/151)\u001b[K\rremote: Counting objects:  85% (129/151)\u001b[K\rremote: Counting objects:  86% (130/151)\u001b[K\rremote: Counting objects:  87% (132/151)\u001b[K\rremote: Counting objects:  88% (133/151)\u001b[K\rremote: Counting objects:  89% (135/151)\u001b[K\rremote: Counting objects:  90% (136/151)\u001b[K\rremote: Counting objects:  91% (138/151)\u001b[K\rremote: Counting objects:  92% (139/151)\u001b[K\rremote: Counting objects:  93% (141/151)\u001b[K\rremote: Counting objects:  94% (142/151)\u001b[K\rremote: Counting objects:  95% (144/151)\u001b[K\rremote: Counting objects:  96% (145/151)\u001b[K\rremote: Counting objects:  97% (147/151)\u001b[K\rremote: Counting objects:  98% (148/151)\u001b[K\rremote: Counting objects:  99% (150/151)\u001b[K\rremote: Counting objects: 100% (151/151)\u001b[K\rremote: Counting objects: 100% (151/151), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/97)\u001b[K\rremote: Compressing objects:   2% (2/97)\u001b[K\rremote: Compressing objects:   3% (3/97)\u001b[K\rremote: Compressing objects:   4% (4/97)\u001b[K\rremote: Compressing objects:   5% (5/97)\u001b[K\rremote: Compressing objects:   6% (6/97)\u001b[K\rremote: Compressing objects:   7% (7/97)\u001b[K\rremote: Compressing objects:   8% (8/97)\u001b[K\rremote: Compressing objects:   9% (9/97)\u001b[K\rremote: Compressing objects:  10% (10/97)\u001b[K\rremote: Compressing objects:  11% (11/97)\u001b[K\rremote: Compressing objects:  12% (12/97)\u001b[K\rremote: Compressing objects:  13% (13/97)\u001b[K\rremote: Compressing objects:  14% (14/97)\u001b[K\rremote: Compressing objects:  15% (15/97)\u001b[K\rremote: Compressing objects:  16% (16/97)\u001b[K\rremote: Compressing objects:  17% (17/97)\u001b[K\rremote: Compressing objects:  18% (18/97)\u001b[K\rremote: Compressing objects:  19% (19/97)\u001b[K\rremote: Compressing objects:  20% (20/97)\u001b[K\rremote: Compressing objects:  21% (21/97)\u001b[K\rremote: Compressing objects:  22% (22/97)\u001b[K\rremote: Compressing objects:  23% (23/97)\u001b[K\rremote: Compressing objects:  24% (24/97)\u001b[K\rremote: Compressing objects:  25% (25/97)\u001b[K\rremote: Compressing objects:  26% (26/97)\u001b[K\rremote: Compressing objects:  27% (27/97)\u001b[K\rremote: Compressing objects:  28% (28/97)\u001b[K\rremote: Compressing objects:  29% (29/97)\u001b[K\rremote: Compressing objects:  30% (30/97)\u001b[K\rremote: Compressing objects:  31% (31/97)\u001b[K\rremote: Compressing objects:  32% (32/97)\u001b[K\rremote: Compressing objects:  34% (33/97)\u001b[K\rremote: Compressing objects:  35% (34/97)\u001b[K\rremote: Compressing objects:  36% (35/97)\u001b[K\rremote: Compressing objects:  37% (36/97)\u001b[K\rremote: Compressing objects:  38% (37/97)\u001b[K\rremote: Compressing objects:  39% (38/97)\u001b[K\rremote: Compressing objects:  40% (39/97)\u001b[K\rremote: Compressing objects:  41% (40/97)\u001b[K\rremote: Compressing objects:  42% (41/97)\u001b[K\rremote: Compressing objects:  43% (42/97)\u001b[K\rremote: Compressing objects:  44% (43/97)\u001b[K\rremote: Compressing objects:  45% (44/97)\u001b[K\rremote: Compressing objects:  46% (45/97)\u001b[K\rremote: Compressing objects:  47% (46/97)\u001b[K\rremote: Compressing objects:  48% (47/97)\u001b[K\rremote: Compressing objects:  49% (48/97)\u001b[K\rremote: Compressing objects:  50% (49/97)\u001b[K\rremote: Compressing objects:  51% (50/97)\u001b[K\rremote: Compressing objects:  52% (51/97)\u001b[K\rremote: Compressing objects:  53% (52/97)\u001b[K\rremote: Compressing objects:  54% (53/97)\u001b[K\rremote: Compressing objects:  55% (54/97)\u001b[K\rremote: Compressing objects:  56% (55/97)\u001b[K\rremote: Compressing objects:  57% (56/97)\u001b[K\rremote: Compressing objects:  58% (57/97)\u001b[K\rremote: Compressing objects:  59% (58/97)\u001b[K\rremote: Compressing objects:  60% (59/97)\u001b[K\rremote: Compressing objects:  61% (60/97)\u001b[K\rremote: Compressing objects:  62% (61/97)\u001b[K\rremote: Compressing objects:  63% (62/97)\u001b[K\rremote: Compressing objects:  64% (63/97)\u001b[K\rremote: Compressing objects:  65% (64/97)\u001b[K\rremote: Compressing objects:  67% (65/97)\u001b[K\rremote: Compressing objects:  68% (66/97)\u001b[K\rremote: Compressing objects:  69% (67/97)\u001b[K\rremote: Compressing objects:  70% (68/97)\u001b[K\rremote: Compressing objects:  71% (69/97)\u001b[K\rremote: Compressing objects:  72% (70/97)\u001b[K\rremote: Compressing objects:  73% (71/97)\u001b[K\rremote: Compressing objects:  74% (72/97)\u001b[K\rremote: Compressing objects:  75% (73/97)\u001b[K\rremote: Compressing objects:  76% (74/97)\u001b[K\rremote: Compressing objects:  77% (75/97)\u001b[K\rremote: Compressing objects:  78% (76/97)\u001b[K\rremote: Compressing objects:  79% (77/97)\u001b[K\rremote: Compressing objects:  80% (78/97)\u001b[K\rremote: Compressing objects:  81% (79/97)\u001b[K\rremote: Compressing objects:  82% (80/97)\u001b[K\rremote: Compressing objects:  83% (81/97)\u001b[K\rremote: Compressing objects:  84% (82/97)\u001b[K\rremote: Compressing objects:  85% (83/97)\u001b[K\rremote: Compressing objects:  86% (84/97)\u001b[K\rremote: Compressing objects:  87% (85/97)\u001b[K\rremote: Compressing objects:  88% (86/97)\u001b[K\rremote: Compressing objects:  89% (87/97)\u001b[K\rremote: Compressing objects:  90% (88/97)\u001b[K\rremote: Compressing objects:  91% (89/97)\u001b[K\rremote: Compressing objects:  92% (90/97)\u001b[K\rremote: Compressing objects:  93% (91/97)\u001b[K\rremote: Compressing objects:  94% (92/97)\u001b[K\rremote: Compressing objects:  95% (93/97)\u001b[K\rremote: Compressing objects:  96% (94/97)\u001b[K\rremote: Compressing objects:  97% (95/97)\u001b[K\rremote: Compressing objects:  98% (96/97)\u001b[K\rremote: Compressing objects: 100% (97/97)\u001b[K\rremote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "Receiving objects:   0% (1/1657)   \rReceiving objects:   1% (17/1657)   \rReceiving objects:   2% (34/1657)   \rReceiving objects:   3% (50/1657)   \rReceiving objects:   4% (67/1657)   \rReceiving objects:   5% (83/1657)   \rReceiving objects:   6% (100/1657)   \rReceiving objects:   7% (116/1657)   \rReceiving objects:   8% (133/1657)   \rReceiving objects:   9% (150/1657)   \rReceiving objects:  10% (166/1657)   \rReceiving objects:  11% (183/1657)   \rReceiving objects:  12% (199/1657)   \rReceiving objects:  13% (216/1657)   \rReceiving objects:  14% (232/1657)   \rReceiving objects:  15% (249/1657)   \rReceiving objects:  16% (266/1657)   \rReceiving objects:  17% (282/1657)   \rReceiving objects:  18% (299/1657)   \rReceiving objects:  19% (315/1657)   \rReceiving objects:  20% (332/1657)   \rReceiving objects:  21% (348/1657)   \rReceiving objects:  22% (365/1657)   \rReceiving objects:  23% (382/1657)   \rReceiving objects:  24% (398/1657)   \rReceiving objects:  25% (415/1657)   \rReceiving objects:  26% (431/1657)   \rReceiving objects:  27% (448/1657)   \rReceiving objects:  28% (464/1657)   \rReceiving objects:  29% (481/1657)   \rReceiving objects:  30% (498/1657)   \rReceiving objects:  31% (514/1657)   \rReceiving objects:  32% (531/1657)   \rReceiving objects:  33% (547/1657)   \rReceiving objects:  34% (564/1657)   \rReceiving objects:  35% (580/1657)   \rReceiving objects:  36% (597/1657)   \rReceiving objects:  37% (614/1657)   \rReceiving objects:  38% (630/1657)   \rReceiving objects:  39% (647/1657)   \rReceiving objects:  40% (663/1657)   \rReceiving objects:  41% (680/1657)   \rReceiving objects:  42% (696/1657)   \rReceiving objects:  43% (713/1657)   \rReceiving objects:  44% (730/1657)   \rReceiving objects:  45% (746/1657)   \rReceiving objects:  46% (763/1657)   \rReceiving objects:  47% (779/1657)   \rReceiving objects:  48% (796/1657)   \rReceiving objects:  49% (812/1657)   \rReceiving objects:  50% (829/1657)   \rReceiving objects:  51% (846/1657)   \rReceiving objects:  52% (862/1657)   \rReceiving objects:  53% (879/1657)   \rReceiving objects:  54% (895/1657)   \rReceiving objects:  55% (912/1657)   \rReceiving objects:  56% (928/1657)   \rReceiving objects:  57% (945/1657)   \rReceiving objects:  58% (962/1657)   \rReceiving objects:  59% (978/1657)   \rReceiving objects:  60% (995/1657)   \rReceiving objects:  61% (1011/1657)   \rReceiving objects:  62% (1028/1657)   \rReceiving objects:  63% (1044/1657)   \rReceiving objects:  64% (1061/1657)   \rReceiving objects:  65% (1078/1657)   \rReceiving objects:  66% (1094/1657)   \rReceiving objects:  67% (1111/1657)   \rReceiving objects:  68% (1127/1657)   \rReceiving objects:  69% (1144/1657)   \rReceiving objects:  70% (1160/1657)   \rReceiving objects:  71% (1177/1657)   \rReceiving objects:  72% (1194/1657)   \rReceiving objects:  73% (1210/1657)   \rReceiving objects:  74% (1227/1657)   \rReceiving objects:  75% (1243/1657)   \rReceiving objects:  76% (1260/1657)   \rReceiving objects:  77% (1276/1657)   \rReceiving objects:  78% (1293/1657)   \rReceiving objects:  79% (1310/1657)   \rReceiving objects:  80% (1326/1657)   \rReceiving objects:  81% (1343/1657)   \rReceiving objects:  82% (1359/1657)   \rReceiving objects:  83% (1376/1657)   \rReceiving objects:  84% (1392/1657)   \rReceiving objects:  85% (1409/1657)   \rReceiving objects:  86% (1426/1657)   \rReceiving objects:  87% (1442/1657)   \rReceiving objects:  88% (1459/1657)   \rReceiving objects:  89% (1475/1657)   \rReceiving objects:  90% (1492/1657)   \rReceiving objects:  91% (1508/1657)   \rReceiving objects:  92% (1525/1657)   \rReceiving objects:  93% (1542/1657)   \rReceiving objects:  94% (1558/1657)   \rReceiving objects:  95% (1575/1657)   \rReceiving objects:  96% (1591/1657)   \rremote: Total 1657 (delta 69), reused 107 (delta 49), pack-reused 1506\u001b[K\n",
            "Receiving objects:  97% (1608/1657)   \rReceiving objects:  98% (1624/1657)   \rReceiving objects:  99% (1641/1657)   \rReceiving objects: 100% (1657/1657)   \rReceiving objects: 100% (1657/1657), 511.68 KiB | 8.25 MiB/s, done.\n",
            "Resolving deltas:   0% (0/1122)   \rResolving deltas:   1% (13/1122)   \rResolving deltas:   2% (23/1122)   \rResolving deltas:   3% (36/1122)   \rResolving deltas:   4% (46/1122)   \rResolving deltas:   7% (84/1122)   \rResolving deltas:  10% (120/1122)   \rResolving deltas:  11% (124/1122)   \rResolving deltas:  12% (140/1122)   \rResolving deltas:  13% (146/1122)   \rResolving deltas:  14% (160/1122)   \rResolving deltas:  15% (172/1122)   \rResolving deltas:  17% (195/1122)   \rResolving deltas:  18% (213/1122)   \rResolving deltas:  19% (218/1122)   \rResolving deltas:  22% (253/1122)   \rResolving deltas:  23% (267/1122)   \rResolving deltas:  24% (270/1122)   \rResolving deltas:  26% (302/1122)   \rResolving deltas:  27% (303/1122)   \rResolving deltas:  28% (317/1122)   \rResolving deltas:  29% (336/1122)   \rResolving deltas:  30% (337/1122)   \rResolving deltas:  31% (348/1122)   \rResolving deltas:  32% (362/1122)   \rResolving deltas:  33% (379/1122)   \rResolving deltas:  34% (383/1122)   \rResolving deltas:  35% (396/1122)   \rResolving deltas:  36% (409/1122)   \rResolving deltas:  40% (456/1122)   \rResolving deltas:  41% (463/1122)   \rResolving deltas:  42% (472/1122)   \rResolving deltas:  43% (488/1122)   \rResolving deltas:  44% (496/1122)   \rResolving deltas:  45% (506/1122)   \rResolving deltas:  46% (518/1122)   \rResolving deltas:  47% (528/1122)   \rResolving deltas:  49% (550/1122)   \rResolving deltas:  50% (563/1122)   \rResolving deltas:  52% (584/1122)   \rResolving deltas:  55% (622/1122)   \rResolving deltas:  56% (632/1122)   \rResolving deltas:  57% (649/1122)   \rResolving deltas:  58% (655/1122)   \rResolving deltas:  60% (681/1122)   \rResolving deltas:  63% (708/1122)   \rResolving deltas:  64% (723/1122)   \rResolving deltas:  67% (762/1122)   \rResolving deltas:  68% (768/1122)   \rResolving deltas:  70% (793/1122)   \rResolving deltas:  71% (798/1122)   \rResolving deltas:  72% (813/1122)   \rResolving deltas:  73% (827/1122)   \rResolving deltas:  74% (839/1122)   \rResolving deltas:  75% (842/1122)   \rResolving deltas:  77% (869/1122)   \rResolving deltas:  78% (876/1122)   \rResolving deltas:  79% (895/1122)   \rResolving deltas:  80% (903/1122)   \rResolving deltas:  81% (918/1122)   \rResolving deltas:  82% (925/1122)   \rResolving deltas:  84% (943/1122)   \rResolving deltas:  85% (961/1122)   \rResolving deltas:  86% (967/1122)   \rResolving deltas:  88% (988/1122)   \rResolving deltas:  90% (1015/1122)   \rResolving deltas:  91% (1027/1122)   \rResolving deltas:  92% (1034/1122)   \rResolving deltas:  93% (1044/1122)   \rResolving deltas:  95% (1071/1122)   \rResolving deltas:  96% (1078/1122)   \rResolving deltas:  97% (1091/1122)   \rResolving deltas:  98% (1105/1122)   \rResolving deltas:  99% (1114/1122)   \rResolving deltas: 100% (1122/1122)   \rResolving deltas: 100% (1122/1122), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImXjJTD2JgUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pip install -e ."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJA5ECT-Jjwm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b2b07e1-2973-4ead-d6fe-b114348c9dc5"
      },
      "source": [
        "import os\n",
        "\n",
        "os.listdir()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'sentence-transformers', 'sample_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIHQO_VmJnc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d3072a1-cfbd-4e25-c770-a378e2d1a830"
      },
      "source": [
        "cd sentence-transformers/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/sentence-transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkXksDMXJqCf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e8988c11-b1e8-46c4-ee31-2b3991dd13a1"
      },
      "source": [
        "ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdocs\u001b[0m/      LICENSE     README.md         \u001b[01;34msentence_transformers\u001b[0m/  setup.py\n",
            "\u001b[01;34mexamples\u001b[0m/  NOTICE.txt  requirements.txt  setup.cfg               \u001b[01;34mtests\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyr-a89ZJrOE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "10ee4325-e5f0-41c2-db43-b53649d58728"
      },
      "source": [
        "pip install -e ."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/sentence-transformers\n",
            "Requirement already satisfied: transformers>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.3) (3.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.3) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.3) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.3) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.3) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.3) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence-transformers==0.3.3) (3.2.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.3) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.3) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.3) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.3) (0.1.91)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.3) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.3) (0.8.1rc1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.3) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->sentence-transformers==0.3.3) (20.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.2.0->sentence-transformers==0.3.3) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence-transformers==0.3.3) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence-transformers==0.3.3) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.3) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=3.0.2->sentence-transformers==0.3.3) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=3.0.2->sentence-transformers==0.3.3) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=3.0.2->sentence-transformers==0.3.3) (2.4.7)\n",
            "Installing collected packages: sentence-transformers\n",
            "  Found existing installation: sentence-transformers 0.3.3\n",
            "    Uninstalling sentence-transformers-0.3.3:\n",
            "      Successfully uninstalled sentence-transformers-0.3.3\n",
            "  Running setup.py develop for sentence-transformers\n",
            "Successfully installed sentence-transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piUF-XuyJspU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b1ab7d2-4b7c-467e-fc50-5fdab58db2e0"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 405M/405M [00:24<00:00, 16.5MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j7-K2EaJwnM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = ['This framework generates embeddings for each input sentence',\n",
        "    'Sentences are passed as a list of string.', \n",
        "    'The quick brown fox jumps over the lazy dog.']\n",
        "sentence_embeddings = model.encode(sentences)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0c8taBaKJXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
        "    print(\"Sentence:\", sentence)\n",
        "    print(\"Embedding:\", embedding)\n",
        "    print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ygQpgrDKWKJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhLE2ZDQMuhO",
        "colab_type": "text"
      },
      "source": [
        "### Semantic Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLDJRJ90N_vR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl2FRYiLK8CF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This is a simple application for sentence embeddings: semantic search\n",
        "We have a corpus with various sentences. Then, for a given query sentence,\n",
        "we want to find the most similar sentence in this corpus.\n",
        "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
        "\"\"\"\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n",
        "\n",
        "# Corpus with example sentences\n",
        "corpus = ['A man is eating food.',\n",
        "          'A man is eating a piece of bread.',\n",
        "          'The girl is carrying a baby.',\n",
        "          'A man is riding a horse.',\n",
        "          'A woman is playing violin.',\n",
        "          'Two men pushed carts through the woods.',\n",
        "          'A man is riding a white horse on an enclosed ground.',\n",
        "          'A monkey is playing drums.',\n",
        "          'A cheetah is running behind its prey.'\n",
        "          ]\n",
        "corpus_embeddings = embedder.encode(corpus,) # convert_to_tensor=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjyEIBNpNv61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5fb1dcd2-608a-4da7-870b-35b2baf66c8e"
      },
      "source": [
        "type(corpus_embeddings), corpus_embeddings.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, (9, 768))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e0Fg3VyMUPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Query sentences:\n",
        "queries = ['A man is eating pasta.', 'Someone in a gorilla costume is playing a set of drums.', 'A cheetah chases prey on across a field.']"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9FKTfncPlKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c4eb37d-e410-4866-c495-14582e5f6e58"
      },
      "source": [
        "type(corpus)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwapN1oPPqAn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "6eb2c0bd-fa96-4995-c64a-240472bfea5b"
      },
      "source": [
        "corpus"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A man is eating food.',\n",
              " 'A man is eating a piece of bread.',\n",
              " 'The girl is carrying a baby.',\n",
              " 'A man is riding a horse.',\n",
              " 'A woman is playing violin.',\n",
              " 'Two men pushed carts through the woods.',\n",
              " 'A man is riding a white horse on an enclosed ground.',\n",
              " 'A monkey is playing drums.',\n",
              " 'A cheetah is running behind its prey.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsjL_s75QY-D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2298b6e-2e61-4988-d101-f014360bc20b"
      },
      "source": [
        "query_embedding = embedder.encode(queries[0])\n",
        "type(query_embedding), query_embedding.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, (768,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3_ev7FVQgAI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0ede58a-1716-4722-fbe3-3117665c7166"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "\n",
        "distances = distance.cdist([query_embedding], corpus_embeddings, \"cosine\")[0]\n",
        "min_index = np.argmin(distances)\n",
        "min_distance = distances[min_index]\n",
        "max_similarity = 1 - min_distance\n",
        "\n",
        "max_similarity"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5777363511703955"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "749S9vG1Q6dX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "60808a11-5d76-49c9-9ed2-51f26fc980ce"
      },
      "source": [
        "distances = distance.cdist([query_embedding], corpus_embeddings, \"cosine\")\n",
        "distances"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.42226365, 0.50136387, 1.29761573, 0.84193823, 1.00561219,\n",
              "        0.90084603, 0.85258679, 0.95155343, 0.96996769]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oD7ysyfRAfo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "c7051c33-5c49-43d1-d0b5-dd38f56561c9"
      },
      "source": [
        "top_k = 5\n",
        "for query in queries:\n",
        "    query_embedding = embedder.encode(query) #, convert_to_tensor=True)\n",
        "    \n",
        "    distances = distance.cdist([query_embedding], corpus_embeddings, \"cosine\")\n",
        "\n",
        "    for d in list(distances):\n",
        "        print(d)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.42226365 0.50136387 1.29761573 0.84193823 1.00561219 0.90084603\n",
            " 0.85258679 0.95155343 0.96996769]\n",
            "[0.87602063 0.82807884 1.10474561 0.9906584  0.9900898  0.97112727\n",
            " 0.92935774 0.35648123 0.96478641]\n",
            "[0.94020165 1.03033926 1.03776777 0.78840067 1.01113582 0.91313559\n",
            " 0.75149814 0.81799566 0.2230935 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JMrqpk_SAU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "40768db0-74f6-4f5c-e20f-f1854301e98b"
      },
      "source": [
        "top_k = 5\n",
        "for query in queries:\n",
        "    query_embedding = embedder.encode(query) #, convert_to_tensor=True)\n",
        "    \n",
        "    print(\"cosine scores ==> \",cosine_similarity([query_embedding], corpus_embeddings))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cosine scores ==>  [[ 0.5777364   0.49863607 -0.2976157   0.15806173 -0.00561219  0.09915397\n",
            "   0.1474132   0.04844657  0.0300323 ]]\n",
            "cosine scores ==>  [[ 0.1239794   0.17192118 -0.1047456   0.00934159  0.00991021  0.02887273\n",
            "   0.07064228  0.64351887  0.03521359]]\n",
            "cosine scores ==>  [[ 0.05979835 -0.03033926 -0.03776776  0.2115993  -0.01113583  0.0868644\n",
            "   0.24850187  0.18200433  0.7769065 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndP7ULorSAX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aicoDjv5SAbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5o-VGCGRAlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXLnljZWRAiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ipw9UATBMUSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "a9e2df01-a247-44c5-b455-26d3cdfea228"
      },
      "source": [
        "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
        "top_k = 5\n",
        "for query in queries:\n",
        "    query_embedding = embedder.encode(query) #, convert_to_tensor=True)\n",
        "    \n",
        "    cos_scores = cosine_similarity(query_embedding.reshape(-1,1), corpus_embeddings.reshape(-1,1))\n",
        "\n",
        "    \n",
        "    #We use np.argpartition, to only partially sort the top_k results\n",
        "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
        "\n",
        "    print(\"\\n\\n======================\\n\\n\")\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
        "\n",
        "    for idx in top_results[0:top_k]:\n",
        "        print(idx)\n",
        "        #print(np.array(corpus[idx]).strip(), \"(Score: %.4f)\" % (np.array(cos_scores[idx])))\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: A man is eating pasta.\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "[   0    1    2 ... 6909 6910 6911]\n",
            "[   4   10   12 ... 6909 6910 6911]\n",
            "[   0    1    2 ... 6909 6910 6911]\n",
            "[   0    1    2 ... 6909 6910 6911]\n",
            "[   4   10   12 ... 6909 6910 6911]\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: Someone in a gorilla costume is playing a set of drums.\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "[   0    1    2 ... 6909 6910 6911]\n",
            "[   0    1    2 ... 6909 6910 6911]\n",
            "[   0    1    2 ... 6909 6910 6911]\n",
            "[   4   10   12 ... 6909 6910 6911]\n",
            "[   0    1    2 ... 6909 6910 6911]\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: A cheetah chases prey on across a field.\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "[   4   10   12 ... 6909 6910 6911]\n",
            "[   0    1    2 ... 6909 6910 6911]\n",
            "[   4   10   12 ... 6909 6910 6911]\n",
            "[   0    1    2 ... 6909 6910 6911]\n",
            "[   4   10   12 ... 6909 6910 6911]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omx_5CF3MUVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
        "\n",
        "    #We use np.argpartition, to only partially sort the top_k results\n",
        "    top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
        "\n",
        "    print(\"\\n\\n======================\\n\\n\")\n",
        "    print(\"Query:\", query)\n",
        "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
        "\n",
        "    for idx in top_results[0:top_k]:\n",
        "        print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b_4Q98ZMUw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPXVp8m4K8E8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16e0efcc-917a-4d34-9120-4da0b349b97a"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import os\n",
        "import csv\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "model_name = 'distilbert-base-nli-stsb-quora-ranking'\n",
        "model = SentenceTransformer(model_name)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 245M/245M [00:15<00:00, 15.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f16kG0NK8Ha",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\"\n",
        "dataset_path = \"quora_duplicate_questions.tsv\"\n",
        "max_corpus_size = 100000\n",
        "\n",
        "\n",
        "embedding_cache_path = 'quora-embeddings-{}-size-{}.pkl'.format(model_name.replace('/', '_'), max_corpus_size)\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtKPeaSaLMp4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134,
          "referenced_widgets": [
            "0a3154ddbdaf4387b8be1e365cc10819",
            "b9b34455a34c48efa7e62732a910d993",
            "eb468c05924049d980fd5085b291c9d0",
            "4a5cf94e30a145ce9bc85caca5b900d8",
            "39dd1ad0648f41bcbfe0433a57f07021",
            "3f103bd351154536bfc73c240396e997",
            "ad4354944e2442fc8b7f295551100568",
            "21571df0bc514890b6e96c6d5da2ef6e"
          ]
        },
        "outputId": "91815d0b-5b74-46bc-c4ea-edd7cf180d4e"
      },
      "source": [
        "#Check if embedding cache path exists\n",
        "if not os.path.exists(embedding_cache_path):\n",
        "    # Check if the dataset exists. If not, download and extract\n",
        "    # Download dataset if needed\n",
        "    if not os.path.exists(dataset_path):\n",
        "        print(\"Download dataset\")\n",
        "        util.http_get(url, dataset_path)\n",
        "\n",
        "    # Get all unique sentences from the file\n",
        "    corpus_sentences = set()\n",
        "    with open(dataset_path, encoding='utf8') as fIn:\n",
        "        reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_MINIMAL)\n",
        "        for row in reader:\n",
        "            corpus_sentences.add(row['question1'])\n",
        "            if len(corpus_sentences) >= max_corpus_size:\n",
        "                break\n",
        "\n",
        "            corpus_sentences.add(row['question2'])\n",
        "            if len(corpus_sentences) >= max_corpus_size:\n",
        "                break\n",
        "\n",
        "    corpus_sentences = list(corpus_sentences)\n",
        "    print(\"Encode the corpus. This might take a while\")\n",
        "    corpus_embeddings = model.encode(corpus_sentences, show_progress_bar=True, convert_to_tensor=True)\n",
        "\n",
        "    print(\"Store file on disc\")\n",
        "    with open(embedding_cache_path, \"wb\") as fOut:\n",
        "        pickle.dump({'sentences': corpus_sentences, 'embeddings': corpus_embeddings}, fOut)\n",
        "else:\n",
        "    print(\"Load pre-computed embeddings from disc\")\n",
        "    with open(embedding_cache_path, \"rb\") as fIn:\n",
        "        cache_data = pickle.load(fIn)\n",
        "        corpus_sentences = cache_data['sentences'][0:max_corpus_size]\n",
        "        corpus_embeddings = cache_data['embeddings'][0:max_corpus_size]\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download dataset\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 58.2M/58.2M [00:00<00:00, 81.6MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Encode the corpus. This might take a while\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a3154ddbdaf4387b8be1e365cc10819",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Batches', max=6250.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Store file on disc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6s4mFKmLOax",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ed0cddb-5299-404e-84d8-ac15d1875d19"
      },
      "source": [
        "###############################\n",
        "print(\"Corpus loaded with {} sentences / embeddings\".format(len(corpus_sentences)))\n",
        "\n",
        "while True:\n",
        "    inp_question = input(\"Please enter a question: \")\n",
        "\n",
        "    start_time = time.time()\n",
        "    question_embedding = model.encode(inp_question, convert_to_tensor=True)\n",
        "    hits = util.semantic_search(question_embedding, corpus_embeddings)\n",
        "    end_time = time.time()\n",
        "    hits = hits[0]  #Get the hits for the first query\n",
        "\n",
        "    print(\"Input question:\", inp_question)\n",
        "    print(\"Results (after {:.3f} seconds):\".format(end_time-start_time))\n",
        "    for hit in hits[0:5]:\n",
        "        print(\"\\t{:.3f}\\t{}\".format(hit['score'], corpus_sentences[hit['corpus_id']]))\n",
        "\n",
        "    print(\"\\n\\n========\\n\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus loaded with 100000 sentences / embeddings\n",
            "Please enter a question: What is Quantum Mechanics?\n",
            "Input question: What is Quantum Mechanics?\n",
            "Results (after 0.023 seconds):\n",
            "\t0.828\tWhat is a Quantum?\n",
            "\t0.789\tWhat is systems theory?\n",
            "\t0.789\tWhat's a simple way of explaining quantum physics?\n",
            "\t0.784\tWhat should I read to start learning about quantum mechanics?\n",
            "\t0.774\tWhat is contract theory?\n",
            "\n",
            "\n",
            "========\n",
            "\n",
            "Please enter a question: \n",
            "Input question: \n",
            "Results (after 0.017 seconds):\n",
            "\t0.845\t?\n",
            "\t0.818\t.\n",
            "\t0.655\tWhat is something that I don't know and you know?\n",
            "\t0.644\tWhat is something that you know that I don't?\n",
            "\t0.641\tIs it possible\n",
            "\n",
            "\n",
            "========\n",
            "\n",
            "Please enter a question: exit\n",
            "Input question: exit\n",
            "Results (after 0.018 seconds):\n",
            "\t0.694\tHow do I exit out of Quora?\n",
            "\t0.652\tWhat impact are you wanting to leave on this world?\n",
            "\t0.616\tHow do I get out of Quora permanently?\n",
            "\t0.613\tHow do get out of Quora?\n",
            "\t0.611\tHow can I get out of this thing called Quora?\n",
            "\n",
            "\n",
            "========\n",
            "\n",
            "Please enter a question: !\n",
            "Input question: !\n",
            "Results (after 0.016 seconds):\n",
            "\t0.847\t?\n",
            "\t0.837\t.\n",
            "\t0.759\tWhat?\n",
            "\t0.658\tWhat is the mean?\n",
            "\t0.651\tWhat is what and why is that what?\n",
            "\n",
            "\n",
            "========\n",
            "\n",
            "Please enter a question: a\n",
            "Input question: a\n",
            "Results (after 0.020 seconds):\n",
            "\t0.885\t.\n",
            "\t0.805\t?\n",
            "\t0.680\tWhat?\n",
            "\t0.599\tWhat's mean it?\n",
            "\t0.590\tWhat is something that I don't know and you know?\n",
            "\n",
            "\n",
            "========\n",
            "\n",
            "Please enter a question: what is a qubit?\n",
            "Input question: what is a qubit?\n",
            "Results (after 0.016 seconds):\n",
            "\t0.815\tWhat is a Quantum?\n",
            "\t0.738\tWhat is gravity?\n",
            "\t0.737\tWhat are Bitcoin?\n",
            "\t0.734\tWhat exactly is a particle?\n",
            "\t0.733\tWhat is bitcoin?\n",
            "\n",
            "\n",
            "========\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e951ca050b77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0minp_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter a question: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUc92l0QL0af",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}