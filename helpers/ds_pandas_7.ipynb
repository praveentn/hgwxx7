{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "\n",
    "filename = 'temp.csv'\n",
    "query = 'SELECT * FROM MY_TABLE'\n",
    "connection_object = 'localhost:4545/iusr@vienna'\n",
    "url = 'https://github.com/praveentn/hgwxx7'\n",
    "json_string = \"{'id': 1, 'name': 'praveen' }\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Data\n",
    "pd.read_csv(filename) # From a CSV file\n",
    "\n",
    "pd.read_table(filename) # From a delimited text file (like TSV)\n",
    "\n",
    "pd.read_excel(filename) # From an Excel file\n",
    "\n",
    "pd.read_sql(query, connection_object) # Read from a SQL table/database\n",
    "\n",
    "pd.read_json(json_string) # Read from a JSON formatted string, URL or file.\n",
    "\n",
    "pd.read_html(url) # Parses an html URL, string or file and extracts tables to a list of dataframes\n",
    "\n",
    "pd.read_clipboard() # Takes the contents of your clipboard and passes it to read_table()\n",
    "\n",
    "pd.DataFrame(dict) # From a dict, keys for columns names, values for data as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting Data\n",
    "df.to_csv(filename) # Write to a CSV file\n",
    "\n",
    "df.to_excel(filename) # Write to an Excel file\n",
    "\n",
    "df.to_sql(table_name, connection_object) # Write to a SQL table\n",
    "\n",
    "df.to_json(filename) # Write to a file in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Test Objects\n",
    "# Useful for testing code segements\n",
    "\n",
    "pd.DataFrame(np.random.rand(20,5)) # 5 columns and 20 rows of random floats\n",
    "\n",
    "pd.Series(my_list) # Create a series from an iterable my_list\n",
    "\n",
    "df.index = pd.date_range('2000/1/30', periods=df.shape[0]) # Add a date index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing/Inspecting Data\n",
    "df.head(n) # First n rows of the DataFrame\n",
    "\n",
    "df.tail(n) # Last n rows of the DataFrame\n",
    "\n",
    "df.shape() # Number of rows and columns\n",
    "\n",
    "df.info() # Index, Datatype and Memory information\n",
    "\n",
    "df.describe() # Summary statistics for numerical columns\n",
    "\n",
    "s.value_counts(dropna=False) # View unique values and counts\n",
    "\n",
    "df.apply(pd.Series.value_counts) # Unique values and counts for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection\n",
    "df[col] # Returns column with label col as Series\n",
    "\n",
    "df[[col1, col2]] # Returns columns as a new DataFrame\n",
    "\n",
    "s.iloc[0] # Selection by position\n",
    "\n",
    "s.loc['index_one'] # Selection by index\n",
    "\n",
    "df.iloc[0,:] # First row\n",
    "\n",
    "df.iloc[0,0] # First element of first column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "df.columns = ['a','b','c'] # Rename columns\n",
    "\n",
    "pd.isnull() # Checks for null Values, Returns Boolean Arrray\n",
    "\n",
    "pd.notnull() # Opposite of pd.isnull()\n",
    "\n",
    "df.dropna() # Drop all rows that contain null values\n",
    "\n",
    "df.dropna(axis=1) # Drop all columns that contain null values\n",
    "\n",
    "df.dropna(axis=1,thresh=n) # Drop all rows have have less than n non null values\n",
    "\n",
    "df.fillna(x) # Replace all null values with x\n",
    "\n",
    "s.fillna(s.mean()) # Replace all null values with the mean (mean can be replaced with almost any function from the statistics section)\n",
    "\n",
    "s.astype(float) # Convert the datatype of the series to float\n",
    "\n",
    "s.replace(1, 'one') # Replace all values equal to 1 with 'one'\n",
    "\n",
    "s.replace([1,3],['one', 'three']) # Replace all 1 with 'one' and 3 with 'three'\n",
    "\n",
    "df.rename(columns=lambda x: x + 1) # Mass renaming of columns\n",
    "\n",
    "df.rename(columns={'old_name': 'new_name'}) # Selective renaming\n",
    "\n",
    "df.set_index('column_one') # Change the index\n",
    "\n",
    "df.rename(index=lambda x: x + 1) # Mass renaming of index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter, Sort, and Groupby\n",
    "df[df[col] > 0.5] # Rows where the column col is greater than 0.5\n",
    "\n",
    "df[(df[col] > 0.5) & (df[col] < 0.7)] # Rows where 0.7 > col > 0.5\n",
    "\n",
    "df.sort_values(col1) # Sort values by col1 in ascending order\n",
    "\n",
    "df.sort_values(col2, ascending=False) # Sort values by col2 in descending order\n",
    "\n",
    "df.sort_values([col1, col2], ascending=[True,False]) # Sort values by col1 in ascending order then col2 in descending order\n",
    "\n",
    "df.groupby(col) # Returns a groupby object for values from one column\n",
    "\n",
    "df.groupby([col1, col2]) # Returns groupby object for values from multiple columns\n",
    "\n",
    "df.groupby(col1)[col2] # Returns the mean of the values in col2, grouped by the values in col1 (mean can be replaced with almost any function from the statistics section)\n",
    "\n",
    "df.pivot_table(index=col1, values=[col2,col3], aggfunc=mean) # Create a pivot table that groups by col1 and calculates the mean of col2 and col3\n",
    "\n",
    "df.groupby(col1).agg(np.mean) # Find the average across all columns for every unique col1 group\n",
    "\n",
    "df.apply(np.mean) # Apply the function np.mean() across each column\n",
    "\n",
    "nf.apply(np.max, axis=1) # Apply the function np.max() across each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join/Combine\n",
    "df1.append(df2) # Add the rows in df1 to the end of df2 (columns should be identical)\n",
    "\n",
    "pd.concat([df1, df2],axis=1) # Add the columns in df1 to the end of df2 (rows should be identical)\n",
    "\n",
    "df1.join(df2,on=col1,how='inner') # SQL-style join the columns in df1 with the columns on df2 where the rows for col have identical values. how can be one of 'left', 'right', 'outer', 'inner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "# These can all be applied to a series as well.\n",
    "\n",
    "df.describe() # Summary statistics for numerical columns\n",
    "\n",
    "df.mean() # Returns the mean of all columns\n",
    "\n",
    "df.corr() # Returns the correlation between columns in a DataFrame\n",
    "\n",
    "df.count() # Returns the number of non-null values in each DataFrame column\n",
    "\n",
    "df.max() # Returns the highest value in each column\n",
    "\n",
    "df.min() # Returns the lowest value in each column\n",
    "\n",
    "df.median() # Returns the median of each column\n",
    "\n",
    "df.std() # Returns the standard deviation of each column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
